{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning with Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook is an introductory guide to machine learning and walks you through the Machine Learning process with a sample dataset. You can use your own dataset with some minor adjustments to the code. This notebook provides guidance on how to implement both text and boolean based solutions to machine learning._\n",
    "\n",
    "_This guide only touches on a few machine learning techniques and should not be used as your one-stop-shop for all machine learning problems._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some handy imports for you:\n",
    "\n",
    "#pandas dataframe: data structure \n",
    "import pandas as pd\n",
    "\n",
    "#For text input: bag of words vectorizer - take inverse frequency of words to assign weights\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Training/Test data: split data into training/test data, and specify number of folds for training/test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Validate our models to check performance by calculating different accuracy metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#Specify number of groups we want our data broken up into for training/test data (majority of number is added to training)\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "\n",
    "#5 different classification models - you don't need to use these but they are a great start\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet\n",
    "\n",
    "#accuracy metrics\n",
    "from sklearn.metrics import accuracy_score, explained_variance_score, max_error, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and Set X & y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to connect to a dataset. This can be a local file or a URL. To import your dataset, replace the red URL with the location of the file you want to use.\n",
    "\n",
    "df is a common term for dataframe and is usually standard. You can rename this anything you want - you just have to change all of the occurrences with the new variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to CSV file that contains our data\n",
    "path_to_file = \"https://raw.githubusercontent.com/mawebster9/ThesisCode/master/appeals_query.csv\"\n",
    "\n",
    "#open, read, and store our data into a pandas dataframe\n",
    "df = pd.read_csv(path_to_file, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__***For this template, we will use the terms X_bool, y_bool for the boolean section and X_text, y_text for our text section. It is standard to use just X and y, but in order to show both in one section we need to differentiate them.***__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Boolean Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, we will focus on all of the boolean fields. The boolean fields are all of the true/false values and can account for a lot of different attributes that contain a lot of useful data in a dataset. Our goal is to see if the true/false fields can be used to determine the associated label with high accuracy. For this, our X is all of the true/false fields and its associated label, or y, is the decision field.\n",
    "\n",
    "In this section, we will assign ALL boolean fields to X, set the y, then remove y from X. This is helpful if you have a long list of attributes in your X field and it saves a lot of time and is more dynamic.\n",
    "\n",
    "To use your dataset, replace the red text in y ('Judgment') with the name of your column header that is your decision variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign our attributes to X (all boolean fields) and y\n",
    "X_bool = df.select_dtypes('bool')\n",
    "y_bool = X_bool['Denied']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ensure that our data was read in correctly, we need to check the first value of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the 'Denied' field from the X data frame\n",
    "X_bool = X_bool.drop('Denied',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Smith                     False\n",
       "Female                    False\n",
       "Position_Eligibility      False\n",
       "No_Falsification          False\n",
       "Rebut_Falsification       False\n",
       "Falsification(s)           True\n",
       "Domestic_Violence         False\n",
       "Previous_Clearance        False\n",
       "Traumatic_Life_Event      False\n",
       "Caused_Death              False\n",
       "Child_Sexual_Abuse        False\n",
       "Child_Pornography         False\n",
       "Prostitutes               False\n",
       "Fmr_Military_LawE         False\n",
       "Adverse_Affirmed          False\n",
       "Favorable_Affirmed        False\n",
       "Granted                   False\n",
       "Failed_to_Mitigate        False\n",
       "Success_to_Mitigate       False\n",
       "Adverse_Reversed          False\n",
       "Revoked_Fav_Reversed      False\n",
       "Adverse_Remanded          False\n",
       "Favorable_Remanded        False\n",
       "Remanded_wInstructions    False\n",
       "Recommend_Waiver          False\n",
       "Decision_Other            False\n",
       "Decision_Unknown          False\n",
       "Security_Violations       False\n",
       "Foreign_Influence         False\n",
       "Foreign_Preference        False\n",
       "Sexual_Behavior           False\n",
       "Personal_Conduct           True\n",
       "Financial                 False\n",
       "Alcohol                   False\n",
       "Drugs                      True\n",
       "Emotional_Mental          False\n",
       "Criminal_Conduct           True\n",
       "Handling_PI               False\n",
       "Outside_Activities        False\n",
       "Use_InfoSys               False\n",
       "Deception                 False\n",
       "CAC                       False\n",
       "Unknown_Guideline         False\n",
       "Name: 0, dtype: bool"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the first record in X to verify the previous step\n",
    "X_bool.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bool.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we assigned our columns to X and y variables, we need to transform our X values in a way that a machine learning algorithm can understand it. In order to do this we need to change our true/false values into a numeric format. To do this, we need to change all true values to 1.0 and all false values to 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all instances in X_bool: True = 1.0, False = 0.0\n",
    "X_bool.columns.tolist()\n",
    "for i in (X_bool.columns.tolist()):\n",
    "    X_bool[i] = X_bool[i].replace(True,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that our replacement was successful, we need to print out at least one record in X. We can do so by either of the following 2 ways. The first shows the contents of the top 10 rows - you can change this number to show any amount) and the second just prints out the values for the first record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smith</th>\n",
       "      <th>Female</th>\n",
       "      <th>Position_Eligibility</th>\n",
       "      <th>No_Falsification</th>\n",
       "      <th>Rebut_Falsification</th>\n",
       "      <th>Falsification(s)</th>\n",
       "      <th>Domestic_Violence</th>\n",
       "      <th>Previous_Clearance</th>\n",
       "      <th>Traumatic_Life_Event</th>\n",
       "      <th>Caused_Death</th>\n",
       "      <th>...</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Drugs</th>\n",
       "      <th>Emotional_Mental</th>\n",
       "      <th>Criminal_Conduct</th>\n",
       "      <th>Handling_PI</th>\n",
       "      <th>Outside_Activities</th>\n",
       "      <th>Use_InfoSys</th>\n",
       "      <th>Deception</th>\n",
       "      <th>CAC</th>\n",
       "      <th>Unknown_Guideline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Smith  Female  Position_Eligibility  No_Falsification  Rebut_Falsification  \\\n",
       "0    0.0     0.0                   0.0               0.0                  0.0   \n",
       "1    0.0     1.0                   0.0               1.0                  0.0   \n",
       "2    0.0     0.0                   0.0               1.0                  0.0   \n",
       "3    0.0     0.0                   0.0               1.0                  0.0   \n",
       "4    0.0     0.0                   0.0               0.0                  0.0   \n",
       "5    0.0     0.0                   0.0               1.0                  0.0   \n",
       "6    0.0     0.0                   0.0               0.0                  0.0   \n",
       "7    0.0     0.0                   0.0               1.0                  0.0   \n",
       "8    0.0     0.0                   0.0               1.0                  0.0   \n",
       "9    0.0     0.0                   0.0               0.0                  0.0   \n",
       "\n",
       "   Falsification(s)  Domestic_Violence  Previous_Clearance  \\\n",
       "0               1.0                0.0                 0.0   \n",
       "1               0.0                0.0                 0.0   \n",
       "2               0.0                0.0                 0.0   \n",
       "3               0.0                0.0                 0.0   \n",
       "4               1.0                0.0                 0.0   \n",
       "5               0.0                0.0                 0.0   \n",
       "6               1.0                0.0                 0.0   \n",
       "7               0.0                0.0                 0.0   \n",
       "8               0.0                0.0                 0.0   \n",
       "9               1.0                0.0                 1.0   \n",
       "\n",
       "   Traumatic_Life_Event  Caused_Death  ...  Alcohol  Drugs  Emotional_Mental  \\\n",
       "0                   0.0           0.0  ...      0.0    1.0               0.0   \n",
       "1                   0.0           0.0  ...      0.0    1.0               0.0   \n",
       "2                   0.0           0.0  ...      0.0    1.0               0.0   \n",
       "3                   0.0           0.0  ...      0.0    1.0               0.0   \n",
       "4                   0.0           0.0  ...      1.0    1.0               0.0   \n",
       "5                   0.0           0.0  ...      1.0    0.0               0.0   \n",
       "6                   0.0           0.0  ...      0.0    1.0               0.0   \n",
       "7                   0.0           0.0  ...      1.0    0.0               0.0   \n",
       "8                   0.0           0.0  ...      0.0    0.0               0.0   \n",
       "9                   0.0           0.0  ...      0.0    1.0               0.0   \n",
       "\n",
       "   Criminal_Conduct  Handling_PI  Outside_Activities  Use_InfoSys  Deception  \\\n",
       "0               1.0          0.0                 0.0          0.0        0.0   \n",
       "1               1.0          0.0                 0.0          0.0        0.0   \n",
       "2               0.0          0.0                 0.0          0.0        0.0   \n",
       "3               0.0          0.0                 0.0          0.0        0.0   \n",
       "4               1.0          0.0                 0.0          0.0        0.0   \n",
       "5               0.0          0.0                 0.0          0.0        0.0   \n",
       "6               1.0          0.0                 0.0          0.0        0.0   \n",
       "7               0.0          0.0                 0.0          0.0        0.0   \n",
       "8               1.0          0.0                 0.0          0.0        0.0   \n",
       "9               1.0          0.0                 0.0          0.0        0.0   \n",
       "\n",
       "   CAC  Unknown_Guideline  \n",
       "0  0.0                0.0  \n",
       "1  0.0                0.0  \n",
       "2  0.0                0.0  \n",
       "3  0.0                0.0  \n",
       "4  0.0                0.0  \n",
       "5  0.0                0.0  \n",
       "6  0.0                0.0  \n",
       "7  0.0                0.0  \n",
       "8  0.0                0.0  \n",
       "9  0.0                0.0  \n",
       "\n",
       "[10 rows x 43 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out top 10 records in X to ensure True was changed to 1.0 and False was changed to 0.0\n",
    "X_bool.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Smith                     0.0\n",
       "Female                    0.0\n",
       "Position_Eligibility      0.0\n",
       "No_Falsification          0.0\n",
       "Rebut_Falsification       0.0\n",
       "Falsification(s)          1.0\n",
       "Domestic_Violence         0.0\n",
       "Previous_Clearance        0.0\n",
       "Traumatic_Life_Event      0.0\n",
       "Caused_Death              0.0\n",
       "Child_Sexual_Abuse        0.0\n",
       "Child_Pornography         0.0\n",
       "Prostitutes               0.0\n",
       "Fmr_Military_LawE         0.0\n",
       "Adverse_Affirmed          0.0\n",
       "Favorable_Affirmed        0.0\n",
       "Granted                   0.0\n",
       "Failed_to_Mitigate        0.0\n",
       "Success_to_Mitigate       0.0\n",
       "Adverse_Reversed          0.0\n",
       "Revoked_Fav_Reversed      0.0\n",
       "Adverse_Remanded          0.0\n",
       "Favorable_Remanded        0.0\n",
       "Remanded_wInstructions    0.0\n",
       "Recommend_Waiver          0.0\n",
       "Decision_Other            0.0\n",
       "Decision_Unknown          0.0\n",
       "Security_Violations       0.0\n",
       "Foreign_Influence         0.0\n",
       "Foreign_Preference        0.0\n",
       "Sexual_Behavior           0.0\n",
       "Personal_Conduct          1.0\n",
       "Financial                 0.0\n",
       "Alcohol                   0.0\n",
       "Drugs                     1.0\n",
       "Emotional_Mental          0.0\n",
       "Criminal_Conduct          1.0\n",
       "Handling_PI               0.0\n",
       "Outside_Activities        0.0\n",
       "Use_InfoSys               0.0\n",
       "Deception                 0.0\n",
       "CAC                       0.0\n",
       "Unknown_Guideline         0.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alternatively, you could print the first record in X\n",
    "X_bool.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our X values set up in a way that a machine learning algorithm can understand it, but now we need to fix our y values. In order to do this we need to change our true/false values into a numeric format. To do this, we need to change all true values to 1.0 and all false values to 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace: True = 1.0, False = 0.0\n",
    "y_bool = y_bool.replace(True,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    10862\n",
       "0.0     9652\n",
       "Name: Denied, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out counts for all y records - ensure that our replace statement worked\n",
    "y_bool.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alternatively, you could print the first record in y\n",
    "y_bool.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Text Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is assigning our data to our variables. X is all of the attributes we want to feed through our ML algorithm and y is our label (value we are trying to predict). To store your dataset, replace the red text with the column headers you want. For this I am only using one field for the X variable ('Judgment') and my y is the associated label for that column ('Denied').\n",
    "\n",
    "For this section, we will focus solely on the a text input field. The 'Judgment' field acts like a brief story summary field that contains a lot of useful data surrounding our dataset. Our goal is to see if the 'Judgment' field can be used to determine whether the X data can be used to determine the outcome (y) with high accuracy. For this, our X is the 'Judgment' field and its associated label, or y, is the 'Denied field.\n",
    "\n",
    "Also note, if you have a large dataset you need to reduce the number of entries since processing text data is very bulky. If done with all data in a large dataset, you might get a memory error. For this example, 500 records has enough data to make a reasonably accurate model but not too much where there is not enough memory.\n",
    "\n",
    "**This depends on the dataset being used, you can play around to make this high enough that you don't get a memory error - I typically use 500.**\n",
    "\n",
    "Also note, our y data is in Boolean format so we do not need to worry about the bag of words for it.\n",
    "\n",
    "Make sure that when you truncate the dataset, you truncate __BOTH__ the X and y variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign our attributes to X and y - only taking the first 500 records\n",
    "X_text = df['Judgment'].head(500)\n",
    "y_text = df['Denied'].head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ensure that our data was read in correctly, we need to check the first value of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Applicant's drug abuse was not mitigated where marijuana use was recent, and had continued after Applicant stated an intent to refrain from drug use in the future. He falsified his drug abuse history on security questionnaires in March and October 1995 an\""
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the first record in X to verify the previous step\n",
    "X_text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_text.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data assigned to our X and y variables, it is time to prime the data for the machine learning algorithms. For text data, we need to break up the words in a way that a machine can understand the characteristics of speech. One of the ways we can do this is by using a bag of words. A bag of words essentially takes a large amount of text data and separates the values into separate words and counts the number of occurrences of each word. \n",
    "\n",
    "For this example, we will be using a vectorizer to split the words and calculate the number of occurrences for each word. The vectorizer we will use in this example, TfidfVectorizer, works by counting the inverse frequency of the words found in the judgment field to assign a weight for each word. This ensures that common words, also known as \"stop words\", found in the english language, like \"the\", \"a\", \"an\", etc., are weighted less than words that are unique for this dataset, such as \"foreign\", \"alcohol\", \"drugs\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up bag of words for judgment field, use english stop words\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_text = vectorizer.fit_transform(X_text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '10',\n",
       " '1001',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '154',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '1959',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1969',\n",
       " '1970',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '199',\n",
       " '1990',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '20',\n",
       " '2001',\n",
       " '2003',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '203',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '33',\n",
       " '35',\n",
       " '36',\n",
       " '38',\n",
       " '40',\n",
       " '401k',\n",
       " '45',\n",
       " '50',\n",
       " '548',\n",
       " '59',\n",
       " '60',\n",
       " '700',\n",
       " '80',\n",
       " '81',\n",
       " '83',\n",
       " '86',\n",
       " '88',\n",
       " '91',\n",
       " '94',\n",
       " '96',\n",
       " 'a10',\n",
       " 'aa',\n",
       " 'ab',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolutely',\n",
       " 'absolve',\n",
       " 'absolving',\n",
       " 'absorb',\n",
       " 'abstain',\n",
       " 'abstained',\n",
       " 'abstention',\n",
       " 'abstin',\n",
       " 'abstinence',\n",
       " 'abstinent',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'ac',\n",
       " 'accept',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accrued',\n",
       " 'accumulated',\n",
       " 'acquittal',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictions',\n",
       " 'addictive',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'addressing',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adjudicate',\n",
       " 'adjudication',\n",
       " 'adjudications',\n",
       " 'adjudicative',\n",
       " 'adm',\n",
       " 'administ',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administrative',\n",
       " 'administratively',\n",
       " 'admissibility',\n",
       " 'admissions',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admitting',\n",
       " 'adoption',\n",
       " 'adulterated',\n",
       " 'adv',\n",
       " 'adver',\n",
       " 'advers',\n",
       " 'adverse',\n",
       " 'advised',\n",
       " 'affect',\n",
       " 'affir',\n",
       " 'affirmatively',\n",
       " 'affirmed',\n",
       " 'afraid',\n",
       " 'afte',\n",
       " 'aftercare',\n",
       " 'ag',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agents',\n",
       " 'aggravated',\n",
       " 'aggregate',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'aid',\n",
       " 'alc',\n",
       " 'alcoho',\n",
       " 'alcohol',\n",
       " 'alcoholics',\n",
       " 'alcoholism',\n",
       " 'alford',\n",
       " 'allegation',\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'almist',\n",
       " 'alter',\n",
       " 'alternate',\n",
       " 'altho',\n",
       " 'amd',\n",
       " 'amend',\n",
       " 'american',\n",
       " 'amounting',\n",
       " 'amphetamine',\n",
       " 'amphetamines',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'anecdotal',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'anonymous',\n",
       " 'answer',\n",
       " 'answers',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'appe',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appellate',\n",
       " 'appli',\n",
       " 'appliance',\n",
       " 'applic',\n",
       " 'applicable',\n",
       " 'applican',\n",
       " 'applicant',\n",
       " 'applicants',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'appllicant',\n",
       " 'apply',\n",
       " 'appropriate',\n",
       " 'approximately',\n",
       " 'april',\n",
       " 'ar',\n",
       " 'arbitrary',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arrangements',\n",
       " 'arrearages',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arrests',\n",
       " 'article',\n",
       " 'articulate',\n",
       " 'asdc3i',\n",
       " 'assault',\n",
       " 'assaulted',\n",
       " 'assertion',\n",
       " 'assertions',\n",
       " 'assessed',\n",
       " 'assessing',\n",
       " 'assessment',\n",
       " 'assets',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assuming',\n",
       " 'assumptions',\n",
       " 'attempted',\n",
       " 'attempts',\n",
       " 'attend',\n",
       " 'attendance',\n",
       " 'attended',\n",
       " 'attendi',\n",
       " 'attends',\n",
       " 'attorney',\n",
       " 'attributable',\n",
       " 'august',\n",
       " 'authorities',\n",
       " 'authority',\n",
       " 'authorized',\n",
       " 'authorizing',\n",
       " 'automatic',\n",
       " 'automobile',\n",
       " 'available',\n",
       " 'averment',\n",
       " 'avers',\n",
       " 'avoid',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'awards',\n",
       " 'away',\n",
       " 'background',\n",
       " 'backing',\n",
       " 'balance',\n",
       " 'bank',\n",
       " 'bankruptcies',\n",
       " 'bankruptcy',\n",
       " 'bare',\n",
       " 'based',\n",
       " 'basing',\n",
       " 'basis',\n",
       " 'battery',\n",
       " 'bears',\n",
       " 'beca',\n",
       " 'beer',\n",
       " 'beers',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behavior',\n",
       " 'behavioral',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'believes',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'bias',\n",
       " 'bills',\n",
       " 'binding',\n",
       " 'binge',\n",
       " 'binging',\n",
       " 'birth',\n",
       " 'bizarre',\n",
       " 'blackmail',\n",
       " 'bo',\n",
       " 'boar',\n",
       " 'board',\n",
       " 'bodies',\n",
       " 'body',\n",
       " 'born',\n",
       " 'bound',\n",
       " 'boy',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brings',\n",
       " 'broadly',\n",
       " 'brought',\n",
       " 'burden',\n",
       " 'burdens',\n",
       " 'business',\n",
       " 'called',\n",
       " 'came',\n",
       " 'candid',\n",
       " 'candor',\n",
       " 'capricious',\n",
       " 'card',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'carefully',\n",
       " 'carry',\n",
       " 'carrying',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'catastrophic',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'ceased',\n",
       " 'ceasing',\n",
       " 'certain',\n",
       " 'chairman',\n",
       " 'challenge',\n",
       " 'challenged',\n",
       " 'chance',\n",
       " 'chances',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'chapter',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charges',\n",
       " 'check',\n",
       " 'chemical',\n",
       " 'child',\n",
       " 'children',\n",
       " 'cho',\n",
       " 'chosen',\n",
       " 'chronic',\n",
       " 'church',\n",
       " 'cigarettes',\n",
       " 'circumstances',\n",
       " 'circumstant',\n",
       " 'circumstantial',\n",
       " 'cite',\n",
       " 'cited',\n",
       " 'citizen',\n",
       " 'citizensh',\n",
       " 'citizenshi',\n",
       " 'citizenship',\n",
       " 'civil',\n",
       " 'cl',\n",
       " 'claim',\n",
       " 'claimed',\n",
       " 'claiming',\n",
       " 'claims',\n",
       " 'clarity',\n",
       " 'classifi',\n",
       " 'classified',\n",
       " 'cle',\n",
       " 'clea',\n",
       " 'clear',\n",
       " 'cleara',\n",
       " 'clearanc',\n",
       " 'clearance',\n",
       " 'clearances',\n",
       " 'clearly',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closing',\n",
       " 'closure',\n",
       " 'cloud',\n",
       " 'cocaine',\n",
       " 'code',\n",
       " 'coercion',\n",
       " 'collateral',\n",
       " 'collaterally',\n",
       " 'colleagues',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'commencing',\n",
       " 'commit',\n",
       " 'commitment',\n",
       " 'committed',\n",
       " 'committing',\n",
       " 'common',\n",
       " 'commonly',\n",
       " 'communications',\n",
       " 'company',\n",
       " 'compel',\n",
       " 'compl',\n",
       " 'complain',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completion',\n",
       " 'compliance',\n",
       " 'complicated',\n",
       " 'complied',\n",
       " 'compliment',\n",
       " 'comply',\n",
       " 'computer',\n",
       " 'conceal',\n",
       " 'concealed',\n",
       " 'concealing',\n",
       " 'concealment',\n",
       " 'concept',\n",
       " 'concerning',\n",
       " 'concerns',\n",
       " 'conclude',\n",
       " 'concluded',\n",
       " 'concluding',\n",
       " 'conclusion',\n",
       " 'conclusions',\n",
       " 'conclusive',\n",
       " 'condit',\n",
       " 'conditi',\n",
       " 'condition',\n",
       " 'conditional',\n",
       " 'conditions',\n",
       " 'conduct',\n",
       " 'confession',\n",
       " 'confidenc',\n",
       " 'confidence',\n",
       " 'confidential',\n",
       " 'confined',\n",
       " 'conflicting',\n",
       " 'confront',\n",
       " 'confronted',\n",
       " 'confusion',\n",
       " 'conjunction',\n",
       " 'consequences',\n",
       " 'consider',\n",
       " 'considerable',\n",
       " 'consideration',\n",
       " 'considerations',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'consisting',\n",
       " 'consolidate',\n",
       " 'constitute',\n",
       " 'constitutes',\n",
       " 'constitutionality',\n",
       " 'construed',\n",
       " 'consume',\n",
       " 'consumed',\n",
       " 'consumer',\n",
       " 'consuming',\n",
       " 'consumption',\n",
       " 'contact',\n",
       " 'contacting',\n",
       " 'contacts',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'contend',\n",
       " 'contending',\n",
       " 'continuating',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'continues',\n",
       " 'continuing',\n",
       " 'continuous',\n",
       " 'contract',\n",
       " 'contractor',\n",
       " 'contradict',\n",
       " 'contradictory',\n",
       " 'contrary',\n",
       " 'contribution',\n",
       " 'control',\n",
       " 'controverted',\n",
       " 'convicted',\n",
       " 'conviction',\n",
       " 'convictions',\n",
       " 'convince',\n",
       " 'convinced',\n",
       " 'convinces',\n",
       " 'cooperation',\n",
       " 'copied',\n",
       " 'copyrighted',\n",
       " 'corporal',\n",
       " 'correct',\n",
       " 'correspondence',\n",
       " 'corroborate',\n",
       " 'corroborative',\n",
       " 'counsel',\n",
       " 'counseling',\n",
       " 'counselor',\n",
       " 'counterfeiting',\n",
       " 'countries',\n",
       " 'country',\n",
       " 'counts',\n",
       " 'couple',\n",
       " 'coupled',\n",
       " 'course',\n",
       " 'court',\n",
       " 'courts',\n",
       " 'covered',\n",
       " 'coworkers',\n",
       " 'cr',\n",
       " 'crack',\n",
       " 'crank',\n",
       " 'crash',\n",
       " 'created',\n",
       " 'cred',\n",
       " 'credentialed',\n",
       " 'credibility',\n",
       " 'credible',\n",
       " 'credibly',\n",
       " 'credit',\n",
       " 'credited',\n",
       " 'creditors',\n",
       " 'crime',\n",
       " 'crimes',\n",
       " 'criminal',\n",
       " 'criminally',\n",
       " 'criter',\n",
       " 'criterion',\n",
       " 'cross',\n",
       " 'crystal',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'daily',\n",
       " 'dangerous',\n",
       " 'dangers',\n",
       " 'date',\n",
       " 'dated',\n",
       " 'daughter',\n",
       " 'daughters',\n",
       " 'day',\n",
       " 'days',\n",
       " 'deadline',\n",
       " 'dealing',\n",
       " 'death',\n",
       " 'deb',\n",
       " 'debt',\n",
       " 'debts',\n",
       " 'dec',\n",
       " 'decades',\n",
       " 'december',\n",
       " 'decemnber',\n",
       " 'deceptive',\n",
       " 'decide',\n",
       " 'deciding',\n",
       " 'decision',\n",
       " 'decisions',\n",
       " 'decisive',\n",
       " 'declaration',\n",
       " 'declared',\n",
       " 'decline',\n",
       " 'defe',\n",
       " 'defect',\n",
       " 'defendants',\n",
       " 'defense',\n",
       " 'deference',\n",
       " 'defraud',\n",
       " 'degree',\n",
       " 'delegated',\n",
       " 'deliberate',\n",
       " 'deliberately',\n",
       " 'delinquency',\n",
       " 'delinquent',\n",
       " 'demeanor',\n",
       " 'demo',\n",
       " 'demonstr',\n",
       " 'demonstrate',\n",
       " 'demonstrated',\n",
       " 'demonstrates',\n",
       " 'demonstrating',\n",
       " 'den',\n",
       " 'denial',\n",
       " 'denials',\n",
       " 'denied',\n",
       " 'denies',\n",
       " 'deny',\n",
       " 'department',\n",
       " 'dependence',\n",
       " 'dependency',\n",
       " 'dependent',\n",
       " 'depression',\n",
       " 'deprives',\n",
       " 'depth',\n",
       " 'designed',\n",
       " 'desk',\n",
       " 'despite',\n",
       " 'destroyed',\n",
       " 'details',\n",
       " 'detained',\n",
       " 'detection',\n",
       " 'determination',\n",
       " 'determinations',\n",
       " 'determine',\n",
       " 'determining',\n",
       " 'detoxification',\n",
       " 'detracts',\n",
       " 'deviate',\n",
       " 'deviates',\n",
       " 'device',\n",
       " 'devotion',\n",
       " 'diagnosed',\n",
       " 'diagnoses',\n",
       " 'diagnosis',\n",
       " 'did',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'difficulties',\n",
       " 'diminish',\n",
       " 'direction',\n",
       " 'directive',\n",
       " 'directly',\n",
       " 'dis',\n",
       " 'disavow',\n",
       " 'disavowed',\n",
       " 'discern',\n",
       " 'discharge',\n",
       " 'discharged',\n",
       " 'discharging',\n",
       " 'disclose',\n",
       " 'disclosed',\n",
       " 'disclosure',\n",
       " 'discontinued',\n",
       " 'discount',\n",
       " 'discretion',\n",
       " 'discuss',\n",
       " 'dishonest',\n",
       " 'dishonesty',\n",
       " 'disintegrating',\n",
       " 'dismiss',\n",
       " 'dismissed',\n",
       " 'disorder',\n",
       " 'disparate',\n",
       " 'dispel',\n",
       " 'disposed',\n",
       " 'dispositive',\n",
       " 'disproving',\n",
       " 'dispute',\n",
       " 'disputes',\n",
       " 'disq',\n",
       " 'disqualifying',\n",
       " 'dissatisfaction',\n",
       " 'distant',\n",
       " 'distribu',\n",
       " 'distribution',\n",
       " 'disturb',\n",
       " 'divorce',\n",
       " 'divorces',\n",
       " 'doctor',\n",
       " 'doctrine',\n",
       " 'document',\n",
       " 'documentary',\n",
       " 'documentation',\n",
       " 'documented',\n",
       " 'documents',\n",
       " 'dod',\n",
       " 'does',\n",
       " 'doha',\n",
       " 'doing',\n",
       " 'domestic',\n",
       " 'doubts',\n",
       " 'downloaded',\n",
       " 'downturn',\n",
       " 'dr',\n",
       " 'drawer',\n",
       " 'drawn',\n",
       " 'drink',\n",
       " 'drinker',\n",
       " 'drinkin',\n",
       " 'drinking',\n",
       " 'drinks',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'dropped',\n",
       " 'drug',\n",
       " 'drugs',\n",
       " 'drunk',\n",
       " 'drunkenness',\n",
       " 'du',\n",
       " 'dual',\n",
       " 'dui',\n",
       " 'duis',\n",
       " 'duration',\n",
       " 'duty',\n",
       " 'dwi',\n",
       " 'e2',\n",
       " 'eaja',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'earn',\n",
       " 'earned',\n",
       " 'earnings',\n",
       " 'education',\n",
       " 'effect',\n",
       " 'effectively',\n",
       " 'effectuate',\n",
       " 'effort',\n",
       " 'efforts',\n",
       " 'eighteen',\n",
       " 'elected',\n",
       " 'elections',\n",
       " 'eligibility',\n",
       " 'eligible',\n",
       " 'em',\n",
       " 'emotional',\n",
       " 'employed',\n",
       " 'employee',\n",
       " 'employees',\n",
       " 'employer',\n",
       " 'employers',\n",
       " 'employment',\n",
       " 'encounter',\n",
       " 'ended',\n",
       " 'ending',\n",
       " 'enforcement',\n",
       " 'engage',\n",
       " 'engaged',\n",
       " 'engages',\n",
       " 'ensuing',\n",
       " 'ensure',\n",
       " 'enter',\n",
       " 'entered',\n",
       " 'enterprise',\n",
       " 'entertain',\n",
       " 'entire',\n",
       " 'entirely',\n",
       " 'entirety',\n",
       " 'entitled',\n",
       " 'entrusted',\n",
       " 'enviro',\n",
       " 'episodes',\n",
       " 'episodic',\n",
       " 'equal',\n",
       " 'err',\n",
       " 'erred',\n",
       " 'erroneous',\n",
       " 'error',\n",
       " 'errors',\n",
       " 'especially',\n",
       " 'est',\n",
       " 'establish',\n",
       " 'established',\n",
       " 'establishes',\n",
       " 'estate',\n",
       " 'estopped',\n",
       " 'estoppel',\n",
       " 'evaluate',\n",
       " 'evaluated',\n",
       " 'evaluation',\n",
       " 'evaluations',\n",
       " 'evasion',\n",
       " 'events',\n",
       " 'eventually',\n",
       " 'evid',\n",
       " 'evidenc',\n",
       " 'evidence',\n",
       " 'evidenced',\n",
       " 'ex',\n",
       " 'examination',\n",
       " 'examine',\n",
       " 'exceeds',\n",
       " 'excepting',\n",
       " 'exception',\n",
       " 'exceptions',\n",
       " 'excess',\n",
       " 'excessive',\n",
       " 'excessively',\n",
       " 'exclude',\n",
       " 'exclusion',\n",
       " 'excuse',\n",
       " 'excused',\n",
       " 'executed',\n",
       " 'exempt',\n",
       " 'exercise',\n",
       " 'exercised',\n",
       " 'exhibit',\n",
       " 'exhibited',\n",
       " 'exhibition',\n",
       " 'exhibits',\n",
       " 'existing',\n",
       " 'expansive',\n",
       " 'expenses',\n",
       " 'experience',\n",
       " 'experimentally',\n",
       " 'experimentation',\n",
       " 'experimented',\n",
       " 'expert',\n",
       " 'expertise',\n",
       " 'explain',\n",
       " 'explanation',\n",
       " 'explanations',\n",
       " 'explicit',\n",
       " 'express',\n",
       " 'expressed',\n",
       " 'expresses',\n",
       " 'extensive',\n",
       " 'extent',\n",
       " 'extenuating',\n",
       " 'extenuation',\n",
       " 'extraordinary',\n",
       " 'face',\n",
       " 'facilitate',\n",
       " 'facility',\n",
       " 'fact',\n",
       " 'factor',\n",
       " 'factors',\n",
       " 'facts',\n",
       " 'factual',\n",
       " 'fail',\n",
       " 'failed',\n",
       " 'failing',\n",
       " 'fails',\n",
       " 'failure',\n",
       " 'failures',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'fairness',\n",
       " 'faith',\n",
       " 'fall',\n",
       " 'falls',\n",
       " 'false',\n",
       " 'falsehoods',\n",
       " 'falsely',\n",
       " 'falsifica',\n",
       " 'falsificat',\n",
       " 'falsificatio',\n",
       " 'falsification',\n",
       " 'falsifications',\n",
       " 'falsified',\n",
       " 'falsify',\n",
       " 'falsifying',\n",
       " 'family',\n",
       " 'fashion',\n",
       " 'father',\n",
       " 'fav',\n",
       " 'favor',\n",
       " 'favorab',\n",
       " 'favorable',\n",
       " 'fc',\n",
       " 'fear',\n",
       " 'february',\n",
       " 'federal',\n",
       " 'fees',\n",
       " 'felony',\n",
       " 'female',\n",
       " 'females',\n",
       " 'file',\n",
       " 'filed',\n",
       " 'filing',\n",
       " 'filings',\n",
       " 'finances',\n",
       " 'financial',\n",
       " 'financially',\n",
       " 'financing',\n",
       " 'findi',\n",
       " 'finding',\n",
       " 'findings',\n",
       " 'fired',\n",
       " 'flawed',\n",
       " 'fo',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'fondling',\n",
       " 'forego',\n",
       " 'forei',\n",
       " 'foreign',\n",
       " 'forgery',\n",
       " 'forgetfulness',\n",
       " 'form',\n",
       " 'forms',\n",
       " 'forth',\n",
       " 'forum',\n",
       " 'founded',\n",
       " 'fourteen',\n",
       " 'frame',\n",
       " 'fraud',\n",
       " 'fraudulent',\n",
       " 'free',\n",
       " 'frequency',\n",
       " 'frequent',\n",
       " 'frequently',\n",
       " 'friends',\n",
       " 'friendships',\n",
       " 'fso',\n",
       " 'fully',\n",
       " 'functioning',\n",
       " 'functions',\n",
       " 'funds',\n",
       " 'furthermore',\n",
       " 'future',\n",
       " 'gained',\n",
       " 'gainfully',\n",
       " 'gambling',\n",
       " 'gave',\n",
       " 'ge',\n",
       " 'general',\n",
       " 'generalized',\n",
       " 'generally',\n",
       " 'generate',\n",
       " 'generated',\n",
       " 'gestures',\n",
       " 'girl',\n",
       " 'given',\n",
       " 'giving',\n",
       " 'glaucoma',\n",
       " 'going',\n",
       " 'good',\n",
       " 'governme',\n",
       " 'government',\n",
       " 'governmental',\n",
       " 'gra',\n",
       " 'grabbing',\n",
       " 'graduate',\n",
       " 'graduati',\n",
       " 'graduation',\n",
       " 'gran',\n",
       " 'granddaughter',\n",
       " 'grant',\n",
       " 'granted',\n",
       " 'granting',\n",
       " 'grave',\n",
       " 'gross',\n",
       " 'grounds',\n",
       " 'group',\n",
       " 'guarantee',\n",
       " 'guarded',\n",
       " 'guidance',\n",
       " 'guideline',\n",
       " 'guidelines',\n",
       " 'guilty',\n",
       " 'habit',\n",
       " 'habitual',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'handled',\n",
       " 'handling',\n",
       " 'harass',\n",
       " 'harassing',\n",
       " 'harassment',\n",
       " 'harmful',\n",
       " 'harmless',\n",
       " 'hashish',\n",
       " 'having',\n",
       " 'hearing',\n",
       " 'hearsay',\n",
       " 'heaviest',\n",
       " 'heavy',\n",
       " 'held',\n",
       " ...]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print bag of words to ensure it is set up correctly\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our list created and number of occurrences counted and weighted appropriately, we need to ensure that the data is all accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2117 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ensure that data is in the right format - TfidfVectorizer returns sparse matrix of type <class numpy.float64>\n",
    "X_text[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2117)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure we have all records that were passed into the vectorizer\n",
    "X_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that all 500 records were passed in and that there were 2,117 unique words in our data that were pulled out, counted, and assigned weights.\n",
    "\n",
    "We have our X values set up in a way that a machine learning algorithm can understand it, but now we need to fix our y values. In order to do this we need to change our true/false values into a numeric format. To do this, we need to change all true values to 1.0 and all false values to 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace: True = 1.0, False = 0.0\n",
    "y_text = y_text.replace(True,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    260\n",
       "1.0    240\n",
       "Name: Denied, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out counts for all y records - ensure that our replace statement worked\n",
    "y_text.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alternatively, you could print the first record in y\n",
    "y_text.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Step-by-Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are sure that our data is good to go, we can begin the process of training our model and predicting outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Run train_test_split() on X & y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is not needed for this notebook but it shows you how the train_test_split function works. Our X and y are randomly split up into training and testing groups. In this case, our test group will be comprised of 33% of the X data(test_size), and will be the same each time we run this line (random_state=42) to ensure consistency between runs.\n",
    "\n",
    "Note that .33 is the standard for test_size and 42 is the standard for random_state. You do not need to use these numbers and can change them.\n",
    "\n",
    "For more guidance on test_size and random_state, visit https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Boolean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break 33% of X and y into X_test and y_test, break other remaining 67% into X_train and y_train\n",
    "X_bool_train, X_bool_test, y_bool_train, y_bool_test = train_test_split(X_bool, y_bool, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13744, 43)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print size of training data (67% of initial data size)\n",
    "X_bool_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6770, 43)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print size of test data (33% of initial data size)\n",
    "X_bool_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the first number in the parenthesis is equal to either 67% (for training data) or 33% (for test data). Take the number in the first column and divide it by the size of your entire dataset that you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Text Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break 33% of X and y into X_test and y_test, break other remaining 67% into X_train and y_train\n",
    "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(X_text, y_text, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335, 2117)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print size of training data (67% of initial data size)\n",
    "X_text_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 2117)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print size of test data (33% of initial data size)\n",
    "X_text_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Run fit() on X_train & y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Boolean Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in our machine learning model is taking our training data and feeding it into an algorithm to build a model. This is essentially the step that teaches an algorithm that for each record X = y. To do this, there are a number of classification models. For this example we will focus on the LogisticRegression classifier.\n",
    "\n",
    "The final step in this section prints out the classifier used as well as all of the parameter values used.\n",
    "\n",
    "For more information on the LogisticRegression classifier, visit https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify which classifier to use and set parameters\n",
    "clf = LogisticRegression(random_state=0, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send X_train and y_train into our classifier to build a model\n",
    "logreg_model_bool = clf.fit(X_bool_train, y_bool_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(logreg_model_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Text Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify which classifier to use and set parameters\n",
    "clf = LogisticRegression(random_state=0, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send X_train and y_train into our classifier to build a model\n",
    "logreg_model_text = clf.fit(X_text_train, y_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(logreg_model_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Run predict() on X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in our model is to take the model we just made using the training data and feeding the test data into it. This will output an array of values that the algorithm has determined to be the decision variable (y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Boolean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send our test data into the model we just created\n",
    "y_bool_pred = logreg_model_bool.predict(X_bool_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the Boolean model's predictions: \n",
      "[0. 1. 0. ... 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "#print our results for the predictions\n",
    "print(\"Here is the Boolean model's predictions: \")\n",
    "print(y_bool_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Text Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send our test data into the model we just created\n",
    "y_text_pred = logreg_model_text.predict(X_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the Text model's predictions: \n",
      "[0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#print our results for the predictions\n",
    "print(\"Here is the Text model's predictions: \")\n",
    "print(y_text_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Verify Accuracy of Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have split our data into training and testing groups, created a model using a machine learning algorithm, and used the model to predict outcomes for our test data, it is time to verify how well our model did compared to the actual outcomes. To do this, there are a number of accuracy metrics. For this example we will focus on the accuracy score.\n",
    "\n",
    "You can use any of the scoring metrics to determine the validity of the model. For more metrics visit https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our score functions\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Boolean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for LogisticRegression classifier on Boolean data:   99.54209748892171 %\n",
      "r2 score for LogisticRegression classifier on Boolean data:   98.1632538037196 %\n"
     ]
    }
   ],
   "source": [
    "#compare y_test values with the predicted y values - formatted to be percent\n",
    "score_bool = accuracy_score(y_bool_test, y_bool_pred).mean()\n",
    "r2_bool = r2_score(y_bool_test, y_bool_pred).mean()\n",
    "print(\"Accuracy score for LogisticRegression classifier on Boolean data:  \", score_bool*100,\"%\")\n",
    "print(\"r2 score for LogisticRegression classifier on Boolean data:  \", r2_bool*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Text Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of our output, we cannot use the accuracy score metric on text data. We can however use other metrics which can be seen in the last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score for LogisticRegression classifier on Boolean data:   98.1632538037196 %\n"
     ]
    }
   ],
   "source": [
    "#compare y_test values with the predicted y values - formatted to be percent\n",
    "r2_bool = r2_score(y_bool_test, y_bool_pred).mean()\n",
    "print(\"r2 score for LogisticRegression classifier on Boolean data:  \", r2_bool*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for Best Classifier to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand how machine learning is done, we can determine which model is the best choice for our data. In this example we will use  different classifiers and evaluate each against 5 accuracy metrics.\n",
    "\n",
    "Note: the cross_val_score() function handles test_train_split(X,y,test_size=33,random_state-42), fit(X_train,y_train), predict(X_test), and also any of the accuracy score metrics. This function is essentially and all-in-one function.\n",
    "\n",
    "We have chosen 5 classifiers to compare with one another on their ability to accurately predict the outcomes. We have also used 5 different validation metrics to determine the model's ability to correctly predict the outcome. For more information on Supervised Machine Learning algorithms visit https://scikit-learn.org/0.16/supervised_learning.html\n",
    "\n",
    "For metric scoring information, visit https://scikit-learn.org/stable/modules/classes.html\n",
    "\n",
    "For classifier information visit\n",
    "* LinearRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "* LogisticRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "* Ridge: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "* Lasso: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "* ElasticNet: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Boolean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* explained_variance score:  0.977941531909747\n",
      "\t* max_error score:  -1.0017213308203534\n",
      "\t* neg_mean_absolute_error score:  -0.014387746769166385\n",
      "\t* neg_mean_squared_error score:  -0.005495523250579351\n",
      "\t* neg_median_absolute_error score:  -0.0024670360377915626\n",
      "\t* r2 score:  0.9779411758438702\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* explained_variance score:  0.9687467054200098\n",
      "\t* max_error score:  -1.0\n",
      "\t* neg_mean_absolute_error score:  -0.007799943748004037\n",
      "\t* neg_mean_squared_error score:  -0.007799943748004037\n",
      "\t* neg_median_absolute_error score:  0.0\n",
      "\t* r2 score:  0.9686913626810804\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* explained_variance score:  0.977671573815401\n",
      "\t* max_error score:  -0.991132998029653\n",
      "\t* neg_mean_absolute_error score:  -0.015787753874918372\n",
      "\t* neg_mean_squared_error score:  -0.005563080770124664\n",
      "\t* neg_median_absolute_error score:  -0.0037896429278965935\n",
      "\t* r2 score:  0.9776700033928963\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* explained_variance score:  0.29315389252649754\n",
      "\t* max_error score:  -0.6143961492081963\n",
      "\t* neg_mean_absolute_error score:  -0.40849994182432364\n",
      "\t* neg_mean_squared_error score:  -0.1761144212409086\n",
      "\t* neg_median_absolute_error score:  -0.3856038507918038\n",
      "\t* r2 score:  0.2930828776388065\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* explained_variance score:  0.0\n",
      "\t* max_error score:  -0.529492054312049\n",
      "\t* neg_mean_absolute_error score:  -0.49826043864686714\n",
      "\t* neg_mean_squared_error score:  -0.24913022021455355\n",
      "\t* neg_median_absolute_error score:  -0.4705079456879509\n",
      "\t* r2 score:  -1.0842509260792591e-08\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LinearRegression(), LogisticRegression(solver='liblinear'), Ridge(alpha=1.0), Lasso(alpha=0.1), ElasticNet()]\n",
    "clf_names = ['LinearRegression', 'LogisticRegression', 'Ridge', 'Lasso', 'ElasticNet']\n",
    "metric_names = ['explained_variance','max_error','neg_mean_absolute_error','neg_mean_squared_error','neg_median_absolute_error','r2']\n",
    "\n",
    "scv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "scores_df = pd.DataFrame(index=metric_names,columns=clf_names)\n",
    "clf_scores = []\n",
    "for clf, name in zip(classifiers, clf_names):\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print('Classifier: ',clf)\n",
    "    print('')\n",
    "    print(\"Scoring Metrics: \")\n",
    "    for metric in metric_names:\n",
    "        score = cross_val_score(clf,X_bool,y_bool,scoring=metric, cv=scv).mean()\n",
    "        clf_scores.append(score)\n",
    "        print('\\t*',metric,'score: ', score)\n",
    "    scores_df[name] = clf_scores\n",
    "    clf_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Text Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* explained_variance score:  0.47439153183285887\n",
      "\t* max_error score:  -0.9703183279520088\n",
      "\t* neg_mean_absolute_error score:  -0.2971181339819032\n",
      "\t* neg_mean_squared_error score:  -0.13352400094515843\n",
      "\t* neg_median_absolute_error score:  -0.2674931862811877\n",
      "\t* r2 score:  0.46503160646305863\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* explained_variance score:  0.3285507440078411\n",
      "\t* max_error score:  -1.0\n",
      "\t* neg_mean_absolute_error score:  -0.19178510448981556\n",
      "\t* neg_mean_squared_error score:  -0.19178510448981556\n",
      "\t* neg_median_absolute_error score:  0.0\n",
      "\t* r2 score:  0.23156018889779914\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* explained_variance score:  0.48287209311059803\n",
      "\t* max_error score:  -0.8470796891915032\n",
      "\t* neg_mean_absolute_error score:  -0.30966373704783756\n",
      "\t* neg_mean_squared_error score:  -0.13198982140733131\n",
      "\t* neg_median_absolute_error score:  -0.28763630266234325\n",
      "\t* r2 score:  0.4711746788692533\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* explained_variance score:  1.8503717077085943e-16\n",
      "\t* max_error score:  -0.5199990409571248\n",
      "\t* neg_mean_absolute_error score:  -0.4992020373305994\n",
      "\t* neg_mean_squared_error score:  -0.24960245885142243\n",
      "\t* neg_median_absolute_error score:  -0.48000095904287515\n",
      "\t* r2 score:  -1.664656556769432e-05\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* explained_variance score:  1.8503717077085943e-16\n",
      "\t* max_error score:  -0.5199990409571248\n",
      "\t* neg_mean_absolute_error score:  -0.4992020373305994\n",
      "\t* neg_mean_squared_error score:  -0.24960245885142243\n",
      "\t* neg_median_absolute_error score:  -0.48000095904287515\n",
      "\t* r2 score:  -1.664656556769432e-05\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LinearRegression(), LogisticRegression(solver='liblinear'), Ridge(alpha=1.0), Lasso(alpha=0.1), ElasticNet()]\n",
    "clf_names = ['LinearRegression', 'LogisticRegression', 'Ridge', 'Lasso', 'ElasticNet']\n",
    "metric_names = ['explained_variance','max_error','neg_mean_absolute_error','neg_mean_squared_error','neg_median_absolute_error','r2']\n",
    "\n",
    "scv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "scores_df = pd.DataFrame(index=metric_names,columns=clf_names)\n",
    "clf_scores = []\n",
    "for clf, name in zip(classifiers, clf_names):\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print('Classifier: ',clf)\n",
    "    print('')\n",
    "    print(\"Scoring Metrics: \")\n",
    "    for metric in metric_names:\n",
    "        score = cross_val_score(clf,X_text.toarray(),y_text,scoring=metric, cv=scv).mean()\n",
    "        clf_scores.append(score)\n",
    "        print('\\t*',metric,'score: ', score)\n",
    "    scores_df[name] = clf_scores\n",
    "    clf_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important that you analyze the model outputs and determine which model performed the best and why. It is also important to mention any bias that may be present in your data and if that could play a roll in the outcomes. It is also important to discuss why you would choose one model over another and which accuracy metrics you used to make your decision.\n",
    "\n",
    "For the metrics we calculated, we really want to focus on the explained_variance_score, the max_error_score, and the r2_score to determine which model is the best. For explained_variance_score, we want the number to be 1 and lower values are worse. For max_error_score, we want the number to be 0. For r2_score, we want the number to be 1 and lower values are worse.\n",
    "\n",
    "In this example, We see that for Boolean based input data, the LinearRegression model gave us the best metric scores (explained_variance_score and r2_score). We see that for the Text based input data, no one particular model gave us the best metrics score - LinearRegression had the best score for explained_variance_score, Lasso and ElasticNet tied for the best max_error_score, and Ridge had the best score for r2_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
